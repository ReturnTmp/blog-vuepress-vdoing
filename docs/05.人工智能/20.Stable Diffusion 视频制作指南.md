---
title: Stable Diffusion 视频制作指南
date: 2023-08-31 21:15:13
permalink: /pages/c35ea1/
categories:
  - 人工智能
tags:
  - 
author: 
  name: ReturnTmp
  link: https://github.com/ReturnTmp
---





## 前言

本文主要是讲解如何使用 Stable Diffusion 制作视频，具体我将会从怎么选底模、Lora、控制模型和调参等方面来讲解

本文基于 AutoDL 平台云端部署 Stable Diffusion Web UI 网站平台，大家可以直接搜索我的相关文章查看部署教程



## 插件方法

### 安装扩充功能

1.首先我们必须保证在命令行参数加入`--enable-insecure-extension-access`才能从图形界面装扩充功能

针对命令行参数和环境变量设置方法

- Linux/macOS：编辑`webui-user.sh`，填入`export 变量=数值`
- Windows：编辑`webui-user.bat`，填入`set 变量=数值`

```bash
export COMMANDLINE_ARGS=--xformers --no-half-vae --medvram
```



2.最简单的方法就是点击Extensions → Available的`Load from:`，就会列出可下载安装的扩充功能，点击安装。

3.有些比较新的扩充功能则是要您拷贝Github保存库网址，并点击选Extensions → `Install from URL`，粘贴网址再按Install，它会自动完成git clone的操作。

4.在安装扩充功能后，都要点击Installed → Apply and restart WebU，重新加载网页界面。有些则是得关掉终端机，重新启动WebUI。

5.如果未来要更新扩充功能，点击Installed → Check for updates，等待下载完成，然后重启WebUI。您可以在这个界面按取消打勾来停用特定的扩充功能。



### mov2mov

官网：[Scholar01/sd-webui-mov2mov](https://github.com/Scholar01/sd-webui-mov2mov)

> 注意：需要先安装 ControlNet 才能使用这个扩充功能

该插件的原理就是我们需要**上传一段视频**，然后该插件将视频**逐一抽出画格**，使用 ControlNet 生图，然后再自动**合成新视频**。可以设置输出的画格率，将人物单独处理。



我们知道AI视频制作的原理就是

### m2m





## 批量图生图处理制作AI视频



## 多帧渲染法 （40系及以上高性能英伟达显卡推荐）



## 加强版多帧渲染法（4090及以上高性能英伟达显卡推荐）







## 补充

推荐一款免费在线 Stable Diffusion 绘图的平台：[LiblibAI·哩布哩布AI-中国领先的AI创作平台](https://www.liblibai.com/)

LiblibAI 网站在线 Stable Diffusion 跑图是每天可以免费跑100张，每天基本很难用完，非常不错

重点是对于小白来说，界面简介，操作易上手，同时平台方面算力十分可观，出图很快





## 参考文章

[【AI绘画及AI视频保姆级教程】用Stable Diffusion制作 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/618648155)

[【保姆级教程】在LiblibAI用免费在线原生界面Stable Diffusion来AI绘画！跑图快、功能强大！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/643651867)

[AI绘图转视频 mov2mov | Stable Diffusion WebUI使用手冊(简体中文)｜Ivon的部落格 (ivonblog.com)](https://ivonblog.com/posts/stable-diffusion-webui-manuals/zh-cn/extensions/sd-webui-mov2mov/)